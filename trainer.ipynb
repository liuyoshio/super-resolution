{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dvice: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from src.datasets import MyDataset\n",
    "from utils.helper import visualize_dataset\n",
    "from utils.config import WorldStrat_path, DEVICE\n",
    "from torch.utils.data import DataLoader\n",
    "from models.network_swinir import SwinIR\n",
    "\n",
    "print(f'Dvice: {DEVICE}')\n",
    "dataset = MyDataset(WorldStrat_path)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiawe\\miniconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscale = 4\n",
    "window_size = 8\n",
    "height = (500 // upscale // window_size + 1) * window_size\n",
    "width = (500 // upscale // window_size + 1) * window_size\n",
    "model = SwinIR(upscale=2, img_size=(height, width),\n",
    "                window_size=window_size, img_range=1., depths=[6, 6, 6, 6],\n",
    "                embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler='pixelshuffledirect')\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model_zoo/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [04:33<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 162/900 [01:16<1:07:12,  5.46s/it]"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def train(epochs, model, dataloader, criterion, optimizer, device, save_path=None):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader):\n",
    "            hr, lr = batch\n",
    "            hr, lr = hr.to(device), lr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(lr)\n",
    "            loss = criterion(output, hr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del hr\n",
    "            del lr\n",
    "\n",
    "        print(f'epoch: {epoch}, loss: {total_loss / len(dataloader)}')\n",
    "        if save_path is not None:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "train(100, model, train_loader, criterion, optimizer, DEVICE, save_path='model_zoo/swinir.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/terry/Desktop/super-resolution/trainer.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     hr, lr \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hr \u001b[39m=\u001b[39m hr\u001b[39m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    hr, lr = batch\n",
    "    hr = hr.to(DEVICE)\n",
    "    lr = lr.to(DEVICE)\n",
    "    res = model(lr)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(hr[0].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title('HR image')\n",
    "    ax[1].imshow(lr[0].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[1].set_title('LR image')\n",
    "    ax[2].imshow(res[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[2].set_title('SR image')\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "467edc1d82b92b2ffb7211bdc470018a0058841a49c371a72ebac196f10e7651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
