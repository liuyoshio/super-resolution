{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dvice: cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/jiawe/Desktop/WorldStrat_hr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/terry/Desktop/super-resolution/trainer.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetwork_swinir\u001b[39;00m \u001b[39mimport\u001b[39;00m SwinIR\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDvice: \u001b[39m\u001b[39m{\u001b[39;00mDEVICE\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m dataset \u001b[39m=\u001b[39m MyDataset(WorldStrat_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/super-resolution/src/datasets.py:14\u001b[0m, in \u001b[0;36mMyDataset.__init__\u001b[0;34m(self, directory_path, downgrading_method)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, directory_path, downgrading_method\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     \u001b[39m# get all file names in the directory\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory_path \u001b[39m=\u001b[39m directory_path\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(directory_path)\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdowngrading_method \u001b[39m=\u001b[39m downgrading_method\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/jiawe/Desktop/WorldStrat_hr'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from src.datasets import MyDataset\n",
    "from utils.helper import visualize_dataset\n",
    "from utils.config import WorldStrat_path, DEVICE\n",
    "from torch.utils.data import DataLoader\n",
    "from models.network_swinir import SwinIR\n",
    "\n",
    "print(f'Dvice: {DEVICE}')\n",
    "dataset = MyDataset(WorldStrat_path)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiawe\\miniconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscale = 4\n",
    "window_size = 8\n",
    "height = (500 // upscale // window_size + 1) * window_size\n",
    "width = (500 // upscale // window_size + 1) * window_size\n",
    "model = SwinIR(upscale=2, img_size=(height, width),\n",
    "                window_size=window_size, img_range=1., depths=[6, 6, 6, 6],\n",
    "                embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler='pixelshuffledirect')\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model_zoo/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [04:33<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 162/900 [01:16<1:07:12,  5.46s/it]"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def train(epochs, model, dataloader, criterion, optimizer, device, save_path=None):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader):\n",
    "            hr, lr = batch\n",
    "            hr, lr = hr.to(device), lr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(lr)\n",
    "            loss = criterion(output, hr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            del output\n",
    "            del hr\n",
    "            del lr\n",
    "\n",
    "        print(f'epoch: {epoch}, loss: {total_loss / len(dataloader)}')\n",
    "        if save_path is not None:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "train(100, model, train_loader, criterion, optimizer, DEVICE, save_path='model_zoo/swinir.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/terry/Desktop/super-resolution/trainer.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     hr, lr \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/terry/Desktop/super-resolution/trainer.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hr \u001b[39m=\u001b[39m hr\u001b[39m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    hr, lr = batch\n",
    "    hr = hr.to(DEVICE)\n",
    "    lr = lr.to(DEVICE)\n",
    "    res = model(lr)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(hr[0].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[0].set_title('HR image')\n",
    "    ax[1].imshow(lr[0].permute(1, 2, 0).cpu().numpy())\n",
    "    ax[1].set_title('LR image')\n",
    "    ax[2].imshow(res[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    ax[2].set_title('SR image')\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "467edc1d82b92b2ffb7211bdc470018a0058841a49c371a72ebac196f10e7651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
